{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39554c2-8e44-471b-9e57-e3557b709dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:40:46 INFO SparkContext: Running Spark version 3.3.0\n",
      "23/12/18 08:40:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/18 08:40:46 INFO ResourceUtils: ==============================================================\n",
      "23/12/18 08:40:46 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/12/18 08:40:46 INFO ResourceUtils: ==============================================================\n",
      "23/12/18 08:40:46 INFO SparkContext: Submitted application: Haha Application\n",
      "23/12/18 08:40:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/12/18 08:40:46 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/12/18 08:40:46 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/12/18 08:40:46 INFO SecurityManager: Changing view acls to: root\n",
      "23/12/18 08:40:46 INFO SecurityManager: Changing modify acls to: root\n",
      "23/12/18 08:40:46 INFO SecurityManager: Changing view acls groups to: \n",
      "23/12/18 08:40:46 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/12/18 08:40:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "23/12/18 08:40:47 INFO Utils: Successfully started service 'sparkDriver' on port 46221.\n",
      "23/12/18 08:40:47 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/12/18 08:40:47 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/12/18 08:40:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/12/18 08:40:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/12/18 08:40:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/12/18 08:40:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-386391d3-e074-420d-ad09-bca0cccef776\n",
      "23/12/18 08:40:47 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "23/12/18 08:40:47 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/12/18 08:40:47 INFO log: Logging initialized @2783ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "23/12/18 08:40:47 INFO Server: jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 11.0.21+9-post-Debian-1deb11u1\n",
      "23/12/18 08:40:47 INFO Server: Started @2944ms\n",
      "23/12/18 08:40:47 INFO AbstractConnector: Started ServerConnector@1ea7f4a6{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "23/12/18 08:40:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "23/12/18 08:40:47 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6e42c82f{/,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:47 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...\n",
      "23/12/18 08:40:48 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 40 ms (0 ms spent in bootstraps)\n",
      "23/12/18 08:40:48 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20231218084048-0000\n",
      "23/12/18 08:40:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44107.\n",
      "23/12/18 08:40:48 INFO NettyBlockTransferService: Server created on spark-master:44107\n",
      "23/12/18 08:40:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/12/18 08:40:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-master, 44107, None)\n",
      "23/12/18 08:40:48 INFO BlockManagerMasterEndpoint: Registering block manager spark-master:44107 with 434.4 MiB RAM, BlockManagerId(driver, spark-master, 44107, None)\n",
      "23/12/18 08:40:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-master, 44107, None)\n",
      "23/12/18 08:40:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-master, 44107, None)\n",
      "23/12/18 08:40:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/0 on worker-20231218083850-172.18.0.4-7000 (172.18.0.4:7000) with 1 core(s)\n",
      "23/12/18 08:40:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/0 on hostPort 172.18.0.4:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:40:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/1 on worker-20231218083851-172.18.0.5-7000 (172.18.0.5:7000) with 1 core(s)\n",
      "23/12/18 08:40:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/1 on hostPort 172.18.0.5:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:40:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/1 is now RUNNING\n",
      "23/12/18 08:40:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/0 is now RUNNING\n",
      "23/12/18 08:40:52 INFO SingleEventLogFileWriter: Logging events to s3a://spark-events/app-20231218084048-0000.inprogress\n",
      "23/12/18 08:40:52 WARN S3ABlockOutputStream: Application invoked the Syncable API against stream writing to app-20231218084048-0000.inprogress. This is Unsupported\n",
      "23/12/18 08:40:52 INFO ContextHandler: Stopped o.s.j.s.ServletContextHandler@6e42c82f{/,null,STOPPED,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@215d59{/jobs,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@a5ad79e{/jobs/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@37b2020f{/jobs/job,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2028152{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@208d618{/stages,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@86b96c3{/stages/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@46c5dce1{/stages/stage,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@58fbe3c8{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@33dfac3{/stages/pool,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@eb0d9b5{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@311f7038{/storage,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@24d2f491{/storage/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@70956653{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@500ad261{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3bfbe799{/environment,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@20113395{/environment/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@19f954bc{/executors,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65216dfe{/executors/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1ec1ec61{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1790577e{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3bbe3b15{/static,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@15bef60f{/,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@19b2d2df{/api,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1647dcef{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3aba8d74{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@22e3f400{/metrics/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:40:52 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "23/12/18 08:40:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:43480) with ID 1,  ResourceProfileId 0\n",
      "23/12/18 08:40:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:39154) with ID 0,  ResourceProfileId 0\n",
      "23/12/18 08:40:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:38519 with 127.2 MiB RAM, BlockManagerId(1, 172.18.0.5, 38519, None)\n",
      "23/12/18 08:40:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:35955 with 127.2 MiB RAM, BlockManagerId(0, 172.18.0.4, 35955, None)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"Haha Application\"). \\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7da78f2-4dcb-497d-a7ab-c8b3d2acf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c245fc6-9eb9-48c3-80ef-4b340b3ea7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.eventLog.enabled : true\n",
      "spark.app.startTime : 1702888846587\n",
      "spark.hadoop.fs.s3a.connection.ssl.enabled : false\n",
      "spark.driver.extraJavaOptions : -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\n",
      "spark.eventLog.dir : s3a://spark-events/\n",
      "spark.hadoop.fs.s3a.path.style.access : true\n",
      "spark.master : spark://spark-master:7077\n",
      "spark.hadoop.fs.s3a.access.key : minioadmin\n",
      "spark.serializer.objectStreamReset : 100\n",
      "spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a : org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory\n",
      "spark.submit.deployMode : client\n",
      "spark.history.fs.logDirectory : s3a://spark-events/\n",
      "spark.ui.proxyBase : /proxy/app-20231218084048-0000\n",
      "spark.app.name : Haha Application\n",
      "spark.ui.reverseProxy : true\n",
      "spark.hadoop.fs.s3a.secret.key : minioadmin\n",
      "spark.executor.memory : 512m\n",
      "spark.app.submitTime : 1702888846420\n",
      "spark.hadoop.fs.s3a.committer.staging.tmp.path : /tmp/spark_staging\n",
      "spark.driver.host : spark-master\n",
      "spark.executor.id : driver\n",
      "spark.hadoop.fs.s3a.committer.staging.conflict-mode : fail\n",
      "spark.hadoop.fs.s3a.impl : org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "spark.app.id : app-20231218084048-0000\n",
      "spark.driver.port : 46221\n",
      "spark.rdd.compress : True\n",
      "spark.executor.extraJavaOptions : -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\n",
      "spark.submit.pyFiles : \n",
      "spark.hadoop.fs.s3a.committer.name : directory\n",
      "spark.hadoop.fs.s3a.endpoint : http://minio:9000\n",
      "spark.hadoop.fs.s3a.buffer.dir : /tmp/spark_local_buf\n",
      "spark.ui.showConsoleProgress : true\n",
      "spark.hadoop.fs.s3a.attempts.maximum : 0\n"
     ]
    }
   ],
   "source": [
    "conf = spark.sparkContext.getConf().getAll()\n",
    "\n",
    "# Print Configuration\n",
    "for k,v in conf:\n",
    "    print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8e0b93-fa97-47c0-b6a2-bb24760a1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HADOOP_ROOT_LOGGER=WARN,console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "671307e2-df32-42b3-972e-482dc11a3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:49:12 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.5: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "23/12/18 08:49:12 ERROR TaskSchedulerImpl: Lost executor 0 on 172.18.0.4: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "23/12/18 08:49:12 INFO DAGScheduler: Executor lost: 1 (epoch 0)\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.18.0.5, 38519, None)\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor\n",
      "23/12/18 08:49:12 INFO DAGScheduler: Shuffle files lost for executor: 1 (epoch 0)\n",
      "23/12/18 08:49:12 INFO DAGScheduler: Executor lost: 0 (epoch 1)\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.18.0.4, 35955, None)\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor\n",
      "23/12/18 08:49:12 INFO DAGScheduler: Shuffle files lost for executor: 0 (epoch 1)\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/1 is now EXITED (Command exited with code 143)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/1 removed: Command exited with code 143\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removal of executor 1 requested\n",
      "23/12/18 08:49:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/2 on worker-20231218083851-172.18.0.5-7000 (172.18.0.5:7000) with 1 core(s)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/2 on hostPort 172.18.0.5:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/0 is now EXITED (Command exited with code 143)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/0 removed: Command exited with code 143\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removal of executor 0 requested\n",
      "23/12/18 08:49:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/3 on worker-20231218083850-172.18.0.4-7000 (172.18.0.4:7000) with 1 core(s)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/3 on hostPort 172.18.0.4:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/2 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/2 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/4 on worker-20231218083851-172.18.0.5-7000 (172.18.0.5:7000) with 1 core(s)\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removal of executor 2 requested\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/4 on hostPort 172.18.0.5:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 2\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/3 is now FAILED (java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/3 removed: java.lang.IllegalStateException: Shutdown hooks cannot be modified during shutdown.\n",
      "23/12/18 08:49:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.\n",
      "23/12/18 08:49:12 INFO BlockManagerMaster: Removal of executor 3 requested\n",
      "23/12/18 08:49:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 3\n",
      "23/12/18 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20231218084048-0000/5 on worker-20231218083850-172.18.0.4-7000 (172.18.0.4:7000) with 1 core(s)\n",
      "23/12/18 08:49:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20231218084048-0000/5 on hostPort 172.18.0.4:7000 with 1 core(s), 512.0 MiB RAM\n",
      "23/12/18 08:49:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/4 is now LOST (worker lost)\n",
      "23/12/18 08:49:13 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/4 removed: worker lost\n",
      "23/12/18 08:49:13 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.\n",
      "23/12/18 08:49:13 INFO BlockManagerMaster: Removal of executor 4 requested\n",
      "23/12/18 08:49:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 4\n",
      "23/12/18 08:49:13 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20231218083851-172.18.0.5-7000: 172.18.0.5:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO StandaloneSchedulerBackend: Worker worker-20231218083851-172.18.0.5-7000 removed: 172.18.0.5:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO TaskSchedulerImpl: Handle removed worker worker-20231218083851-172.18.0.5-7000: 172.18.0.5:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO DAGScheduler: Shuffle files lost for worker worker-20231218083851-172.18.0.5-7000 on host 172.18.0.5\n",
      "23/12/18 08:49:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20231218084048-0000/5 is now LOST (worker lost)\n",
      "23/12/18 08:49:13 INFO StandaloneSchedulerBackend: Executor app-20231218084048-0000/5 removed: worker lost\n",
      "23/12/18 08:49:13 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20231218083850-172.18.0.4-7000: 172.18.0.4:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO StandaloneSchedulerBackend: Worker worker-20231218083850-172.18.0.4-7000 removed: 172.18.0.4:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.\n",
      "23/12/18 08:49:13 INFO BlockManagerMaster: Removal of executor 5 requested\n",
      "23/12/18 08:49:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 5\n",
      "23/12/18 08:49:13 INFO TaskSchedulerImpl: Handle removed worker worker-20231218083850-172.18.0.4-7000: 172.18.0.4:7000 got disassociated\n",
      "23/12/18 08:49:13 INFO DAGScheduler: Shuffle files lost for worker worker-20231218083850-172.18.0.4-7000 on host 172.18.0.4\n"
     ]
    }
   ],
   "source": [
    "!echo $HADOOP_ROOT_LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f8d38a-5421-4195-addb-e2eb8ea482e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 08:46:41,871 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2023-12-18 08:46:41,980 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2023-12-18 08:46:41,981 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "Found 3 items\n",
      "-rw-rw-rw-   1 root root          0 2023-12-18 08:27 s3a://datalake/yellow_tripdata/2021/01/_SUCCESS\n",
      "-rw-rw-rw-   1 root root   14348091 2023-12-18 08:27 s3a://datalake/yellow_tripdata/2021/01/part-00000-9ce268b1-dab0-4abf-9305-7e74d19b83d7-c000.snappy.parquet\n",
      "-rw-rw-rw-   1 root root   13435961 2023-12-18 08:27 s3a://datalake/yellow_tripdata/2021/01/part-00001-9ce268b1-dab0-4abf-9305-7e74d19b83d7-c000.snappy.parquet\n",
      "2023-12-18 08:46:43,091 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2023-12-18 08:46:43,094 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2023-12-18 08:46:43,095 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls s3a://datalake/yellow_tripdata/2021/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615b5053-3784-4d16-bbf0-ad086e34d8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:42:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "23/12/18 08:42:38 INFO SharedState: Warehouse path is 'file:/opt/workspace/code/spark-warehouse'.\n",
      "23/12/18 08:42:38 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@17dad204{/SQL,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:42:38 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@42b06ecf{/SQL/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:42:38 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7be33d2d{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:42:38 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@48f7a086{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:42:38 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3a70ba93{/static/sql,null,AVAILABLE,@Spark}\n",
      "23/12/18 08:42:39 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.\n",
      "23/12/18 08:42:39 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.\n",
      "23/12/18 08:42:42 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/18 08:42:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "23/12/18 08:42:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "23/12/18 08:42:42 INFO CodeGenerator: Code generated in 131.84703 ms\n",
      "23/12/18 08:42:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 305.3 KiB, free 434.1 MiB)\n",
      "23/12/18 08:42:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 54.1 KiB, free 434.0 MiB)\n",
      "23/12/18 08:42:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-master:44107 (size: 54.1 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:42 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:42:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65087833 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/18 08:42:42 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/18 08:42:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 434.0 MiB)\n",
      "23/12/18 08:42:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.0 MiB)\n",
      "23/12/18 08:42:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-master:44107 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "23/12/18 08:42:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/18 08:42:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "23/12/18 08:42:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()\n",
      "23/12/18 08:42:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:38519 (size: 5.9 KiB, free: 127.2 MiB)\n",
      "23/12/18 08:42:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:38519 (size: 54.1 KiB, free: 127.1 MiB)\n",
      "23/12/18 08:42:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3268 ms on 172.18.0.5 (executor 1) (1/1)\n",
      "23/12/18 08:42:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "23/12/18 08:42:46 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.384 s\n",
      "23/12/18 08:42:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/18 08:42:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "23/12/18 08:42:46 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.433190 s\n",
      "23/12/18 08:42:46 INFO CodeGenerator: Code generated in 14.396683 ms            \n",
      "23/12/18 08:42:46 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/18 08:42:46 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/18 08:42:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "23/12/18 08:42:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 305.3 KiB, free 433.7 MiB)\n",
      "23/12/18 08:42:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 54.1 KiB, free 433.7 MiB)\n",
      "23/12/18 08:42:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-master:44107 (size: 54.1 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:46 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:42:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65087833 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(f\"s3a://{os.environ['MINIO_BUCKET']}/yellow_tripdata_2021-01.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f353139-89d1-45c8-befb-1494babb559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:42:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/18 08:42:52 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/18 08:42:52 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: string, tpep_pickup_datetime: string, tpep_dropoff_datetime: string, passenger_count: string, trip_distance: string ... 16 more fields>\n",
      "23/12/18 08:42:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 305.2 KiB, free 433.4 MiB)\n",
      "23/12/18 08:42:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 54.1 KiB, free 433.3 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-master:44107 (size: 54.1 KiB, free: 434.2 MiB)\n",
      "23/12/18 08:42:52 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:42:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 65087833 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/18 08:42:52 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/18 08:42:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.2 KiB, free 433.3 MiB)\n",
      "23/12/18 08:42:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 433.3 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-master:44107 (size: 6.2 KiB, free: 434.2 MiB)\n",
      "23/12/18 08:42:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "23/12/18 08:42:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/18 08:42:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "23/12/18 08:42:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 4917 bytes) taskResourceAssignments Map()\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on spark-master:44107 in memory (size: 54.1 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:38519 in memory (size: 54.1 KiB, free: 127.2 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-master:44107 in memory (size: 54.1 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on spark-master:44107 in memory (size: 5.9 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:38519 in memory (size: 5.9 KiB, free: 127.2 MiB)\n",
      "23/12/18 08:42:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:38519 (size: 6.2 KiB, free: 127.2 MiB)\n",
      "23/12/18 08:42:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:38519 (size: 54.1 KiB, free: 127.1 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2021-01-01 00:30:10|  2021-01-01 00:36:12|              1|         2.10|         1|                 N|         142|          43|           2|          8|    3|    0.5|         0|           0|                  0.3|        11.8|                 2.5|\n",
      "|       1| 2021-01-01 00:51:20|  2021-01-01 00:52:19|              1|          .20|         1|                 N|         238|         151|           2|          3|  0.5|    0.5|         0|           0|                  0.3|         4.3|                   0|\n",
      "|       1| 2021-01-01 00:43:30|  2021-01-01 01:11:06|              1|        14.70|         1|                 N|         132|         165|           1|         42|  0.5|    0.5|      8.65|           0|                  0.3|       51.95|                   0|\n",
      "|       1| 2021-01-01 00:15:48|  2021-01-01 00:31:01|              0|        10.60|         1|                 N|         138|         132|           1|         29|  0.5|    0.5|      6.05|           0|                  0.3|       36.35|                   0|\n",
      "|       2| 2021-01-01 00:31:49|  2021-01-01 00:48:21|              1|         4.94|         1|                 N|          68|          33|           1|       16.5|  0.5|    0.5|      4.06|           0|                  0.3|       24.36|                 2.5|\n",
      "|       1| 2021-01-01 00:16:29|  2021-01-01 00:24:30|              1|         1.60|         1|                 N|         224|          68|           1|          8|    3|    0.5|      2.35|           0|                  0.3|       14.15|                 2.5|\n",
      "|       1| 2021-01-01 00:00:28|  2021-01-01 00:17:28|              1|         4.10|         1|                 N|          95|         157|           2|         16|  0.5|    0.5|         0|           0|                  0.3|        17.3|                   0|\n",
      "|       1| 2021-01-01 00:12:29|  2021-01-01 00:30:34|              1|         5.70|         1|                 N|          90|          40|           2|         18|    3|    0.5|         0|           0|                  0.3|        21.8|                 2.5|\n",
      "|       1| 2021-01-01 00:39:16|  2021-01-01 01:00:13|              1|         9.10|         1|                 N|          97|         129|           4|       27.5|  0.5|    0.5|         0|           0|                  0.3|        28.8|                   0|\n",
      "|       1| 2021-01-01 00:26:12|  2021-01-01 00:39:46|              2|         2.70|         1|                 N|         263|         142|           1|         12|    3|    0.5|      3.15|           0|                  0.3|       18.95|                 2.5|\n",
      "|       2| 2021-01-01 00:15:52|  2021-01-01 00:38:07|              3|         6.11|         1|                 N|         164|         255|           1|       20.5|  0.5|    0.5|         0|           0|                  0.3|        24.3|                 2.5|\n",
      "|       2| 2021-01-01 00:46:36|  2021-01-01 00:53:45|              2|         1.21|         1|                 N|         255|          80|           1|          7|  0.5|    0.5|      2.49|           0|                  0.3|       10.79|                   0|\n",
      "|       1| 2021-01-01 00:10:46|  2021-01-01 00:32:58|              2|         7.40|         1|                 N|         138|         166|           2|       24.5|  2.5|    0.5|         0|        6.12|                  0.3|       33.92|                   0|\n",
      "|       2| 2021-01-01 00:31:06|  2021-01-01 00:38:52|              5|         1.70|         1|                 N|         142|          50|           1|          8|  0.5|    0.5|      2.36|           0|                  0.3|       14.16|                 2.5|\n",
      "|       2| 2021-01-01 00:42:11|  2021-01-01 00:44:24|              5|          .81|         1|                 N|          50|         142|           2|        4.5|  0.5|    0.5|         0|           0|                  0.3|         8.3|                 2.5|\n",
      "|       2| 2021-01-01 00:17:48|  2021-01-01 00:21:55|              1|         1.01|         1|                 N|         236|         237|           1|        5.5|  0.5|    0.5|         1|           0|                  0.3|        10.3|                 2.5|\n",
      "|       2| 2021-01-01 00:33:38|  2021-01-01 00:38:37|              1|          .73|         1|                 N|         142|         239|           1|        5.5|  0.5|    0.5|      2.79|           0|                  0.3|       12.09|                 2.5|\n",
      "|       2| 2021-01-01 00:47:56|  2021-01-01 00:52:53|              1|         1.17|         1|                 N|         238|         166|           1|        6.5|  0.5|    0.5|      2.06|           0|                  0.3|       12.36|                 2.5|\n",
      "|       2| 2021-01-01 00:04:21|  2021-01-01 00:07:58|              1|          .78|         1|                 N|         239|         238|           1|        4.5|  0.5|    0.5|      1.66|           0|                  0.3|        9.96|                 2.5|\n",
      "|       2| 2021-01-01 00:18:36|  2021-01-01 00:27:10|              2|         1.66|         1|                 N|         151|         142|           2|        8.5|  0.5|    0.5|         0|           0|                  0.3|        12.3|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:42:53 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 424 ms on 172.18.0.5 (executor 1) (1/1)\n",
      "23/12/18 08:42:53 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "23/12/18 08:42:53 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.452 s\n",
      "23/12/18 08:42:53 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/18 08:42:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "23/12/18 08:42:53 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.459720 s\n",
      "23/12/18 08:42:53 INFO CodeGenerator: Code generated in 67.407037 ms\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b6cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet(f\"s3a://{os.environ['MINIO_BUCKET']}/yellow_tripdata/2021/01/\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c5f5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:43:19 INFO InMemoryFileIndex: It took 20 ms to list leaf files for 1 paths.\n",
      "23/12/18 08:43:19 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Got job 2 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/18 08:43:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 154.2 KiB, free 433.9 MiB)\n",
      "23/12/18 08:43:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 56.5 KiB, free 433.8 MiB)\n",
      "23/12/18 08:43:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on spark-master:44107 (size: 56.5 KiB, free: 434.3 MiB)\n",
      "23/12/18 08:43:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "23/12/18 08:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/18 08:43:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "23/12/18 08:43:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 4658 bytes) taskResourceAssignments Map()\n",
      "23/12/18 08:43:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:38519 (size: 56.5 KiB, free: 127.1 MiB)\n",
      "23/12/18 08:43:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 352 ms on 172.18.0.5 (executor 1) (1/1)\n",
      "23/12/18 08:43:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/12/18 08:43:20 INFO DAGScheduler: ResultStage 2 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.373 s\n",
      "23/12/18 08:43:20 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/18 08:43:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "23/12/18 08:43:20 INFO DAGScheduler: Job 2 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.379422 s\n"
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.parquet(f\"s3a://{os.environ['MINIO_BUCKET']}/yellow_tripdata/2021/01/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b322f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:43:27 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/18 08:43:27 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/18 08:43:27 INFO FileSourceStrategy: Output Data Schema: struct<VendorID: string, tpep_pickup_datetime: string, tpep_dropoff_datetime: string, passenger_count: string, trip_distance: string ... 16 more fields>\n",
      "23/12/18 08:43:27 INFO CodeGenerator: Code generated in 44.26068 ms\n",
      "23/12/18 08:43:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 308.8 KiB, free 433.5 MiB)\n",
      "23/12/18 08:43:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 54.6 KiB, free 433.5 MiB)\n",
      "23/12/18 08:43:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on spark-master:44107 (size: 54.6 KiB, free: 434.2 MiB)\n",
      "23/12/18 08:43:27 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:43:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 18086330 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/18 08:43:27 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/18 08:43:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.8 KiB, free 433.4 MiB)\n",
      "23/12/18 08:43:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 433.4 MiB)\n",
      "23/12/18 08:43:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on spark-master:44107 (size: 7.1 KiB, free: 434.2 MiB)\n",
      "23/12/18 08:43:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "23/12/18 08:43:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/18 08:43:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "23/12/18 08:43:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.4, executor 0, partition 0, PROCESS_LOCAL, 4981 bytes) taskResourceAssignments Map()\n",
      "23/12/18 08:43:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.4:35955 (size: 7.1 KiB, free: 127.2 MiB)\n",
      "23/12/18 08:43:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.4:35955 (size: 54.6 KiB, free: 127.1 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2021-01-01 00:30:10|  2021-01-01 00:36:12|              1|         2.10|         1|                 N|         142|          43|           2|          8|    3|    0.5|         0|           0|                  0.3|        11.8|                 2.5|\n",
      "|       1| 2021-01-01 00:51:20|  2021-01-01 00:52:19|              1|          .20|         1|                 N|         238|         151|           2|          3|  0.5|    0.5|         0|           0|                  0.3|         4.3|                   0|\n",
      "|       1| 2021-01-01 00:43:30|  2021-01-01 01:11:06|              1|        14.70|         1|                 N|         132|         165|           1|         42|  0.5|    0.5|      8.65|           0|                  0.3|       51.95|                   0|\n",
      "|       1| 2021-01-01 00:15:48|  2021-01-01 00:31:01|              0|        10.60|         1|                 N|         138|         132|           1|         29|  0.5|    0.5|      6.05|           0|                  0.3|       36.35|                   0|\n",
      "|       2| 2021-01-01 00:31:49|  2021-01-01 00:48:21|              1|         4.94|         1|                 N|          68|          33|           1|       16.5|  0.5|    0.5|      4.06|           0|                  0.3|       24.36|                 2.5|\n",
      "|       1| 2021-01-01 00:16:29|  2021-01-01 00:24:30|              1|         1.60|         1|                 N|         224|          68|           1|          8|    3|    0.5|      2.35|           0|                  0.3|       14.15|                 2.5|\n",
      "|       1| 2021-01-01 00:00:28|  2021-01-01 00:17:28|              1|         4.10|         1|                 N|          95|         157|           2|         16|  0.5|    0.5|         0|           0|                  0.3|        17.3|                   0|\n",
      "|       1| 2021-01-01 00:12:29|  2021-01-01 00:30:34|              1|         5.70|         1|                 N|          90|          40|           2|         18|    3|    0.5|         0|           0|                  0.3|        21.8|                 2.5|\n",
      "|       1| 2021-01-01 00:39:16|  2021-01-01 01:00:13|              1|         9.10|         1|                 N|          97|         129|           4|       27.5|  0.5|    0.5|         0|           0|                  0.3|        28.8|                   0|\n",
      "|       1| 2021-01-01 00:26:12|  2021-01-01 00:39:46|              2|         2.70|         1|                 N|         263|         142|           1|         12|    3|    0.5|      3.15|           0|                  0.3|       18.95|                 2.5|\n",
      "|       2| 2021-01-01 00:15:52|  2021-01-01 00:38:07|              3|         6.11|         1|                 N|         164|         255|           1|       20.5|  0.5|    0.5|         0|           0|                  0.3|        24.3|                 2.5|\n",
      "|       2| 2021-01-01 00:46:36|  2021-01-01 00:53:45|              2|         1.21|         1|                 N|         255|          80|           1|          7|  0.5|    0.5|      2.49|           0|                  0.3|       10.79|                   0|\n",
      "|       1| 2021-01-01 00:10:46|  2021-01-01 00:32:58|              2|         7.40|         1|                 N|         138|         166|           2|       24.5|  2.5|    0.5|         0|        6.12|                  0.3|       33.92|                   0|\n",
      "|       2| 2021-01-01 00:31:06|  2021-01-01 00:38:52|              5|         1.70|         1|                 N|         142|          50|           1|          8|  0.5|    0.5|      2.36|           0|                  0.3|       14.16|                 2.5|\n",
      "|       2| 2021-01-01 00:42:11|  2021-01-01 00:44:24|              5|          .81|         1|                 N|          50|         142|           2|        4.5|  0.5|    0.5|         0|           0|                  0.3|         8.3|                 2.5|\n",
      "|       2| 2021-01-01 00:17:48|  2021-01-01 00:21:55|              1|         1.01|         1|                 N|         236|         237|           1|        5.5|  0.5|    0.5|         1|           0|                  0.3|        10.3|                 2.5|\n",
      "|       2| 2021-01-01 00:33:38|  2021-01-01 00:38:37|              1|          .73|         1|                 N|         142|         239|           1|        5.5|  0.5|    0.5|      2.79|           0|                  0.3|       12.09|                 2.5|\n",
      "|       2| 2021-01-01 00:47:56|  2021-01-01 00:52:53|              1|         1.17|         1|                 N|         238|         166|           1|        6.5|  0.5|    0.5|      2.06|           0|                  0.3|       12.36|                 2.5|\n",
      "|       2| 2021-01-01 00:04:21|  2021-01-01 00:07:58|              1|          .78|         1|                 N|         239|         238|           1|        4.5|  0.5|    0.5|      1.66|           0|                  0.3|        9.96|                 2.5|\n",
      "|       2| 2021-01-01 00:18:36|  2021-01-01 00:27:10|              2|         1.66|         1|                 N|         151|         142|           2|        8.5|  0.5|    0.5|         0|           0|                  0.3|        12.3|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/18 08:43:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 3850 ms on 172.18.0.4 (executor 0) (1/1)\n",
      "23/12/18 08:43:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "23/12/18 08:43:31 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 3.883 s\n",
      "23/12/18 08:43:31 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/18 08:43:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "23/12/18 08:43:31 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 3.888509 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c694b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
